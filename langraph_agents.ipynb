{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import Annotated, TypedDict, List\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage, AnyMessage\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(openai_api_version=os.environ.get(\"AZURE_OPENAI_VERSION\", \"2023-07-01-preview\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt4chat\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"https://gpt-4-trails.openai.azure.com/\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str # The current task human input\n",
    "    plan: str # This is the plan generated by the plan agent\n",
    "    draft: str # This is the draft generated by the writer agent\n",
    "    critique: str # This is the critique generated by the critique agent\n",
    "    content: List[str] # This is the list of documents that tavily has returned\n",
    "    revision_number: int # This is the numeber of revisions made\n",
    "    max_revisions: int # This is the maximum number of revisions allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "Must write to at least one of ['user_profile', 'market_analysis', 'stock_recommendations', 'final_report']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 103\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Run the graph\u001b[39;00m\n\u001b[1;32m    102\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# You can add initial inputs here if needed\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m result \u001b[38;5;241m=\u001b[39m app\u001b[38;5;241m.\u001b[39minvoke(inputs)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_report\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1624\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1623\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1624\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1625\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1626\u001b[0m     config,\n\u001b[1;32m   1627\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1628\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1629\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39minput_keys,\n\u001b[1;32m   1630\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1631\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1632\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1634\u001b[0m ):\n\u001b[1;32m   1635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1636\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1110\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m-> 1110\u001b[0m _panic_or_proceed(done, inflight, step)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1713\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1711\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1712\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1713\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1718\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langgraph/pregel/retry.py:72\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     70\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, task\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langgraph/utils.py:94\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace:\n\u001b[0;32m---> 94\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, merge_configs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, config), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     config \u001b[38;5;241m=\u001b[39m merge_configs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, config)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langchain_core/runnables/base.py:1593\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1590\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1591\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1592\u001b[0m         Output,\n\u001b[0;32m-> 1593\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m   1594\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1596\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1597\u001b[0m             config,\n\u001b[1;32m   1598\u001b[0m             run_manager,\n\u001b[1;32m   1599\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1600\u001b[0m         ),\n\u001b[1;32m   1601\u001b[0m     )\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1603\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langchain_core/runnables/config.py:380\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    379\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langgraph/pregel/write.py:107\u001b[0m, in \u001b[0;36mChannelWrite._write\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    101\u001b[0m values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    102\u001b[0m     (write\u001b[38;5;241m.\u001b[39mchannel, val)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val, write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, entries)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m write\u001b[38;5;241m.\u001b[39mskip_none \u001b[38;5;129;01mor\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    105\u001b[0m ]\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# write packets and values\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_write(\n\u001b[1;32m    108\u001b[0m     config,\n\u001b[1;32m    109\u001b[0m     writes \u001b[38;5;241m+\u001b[39m values,\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_at_least_one_of \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/langgraph/pregel/write.py:157\u001b[0m, in \u001b[0;36mChannelWrite.do_write\u001b[0;34m(config, values, require_at_least_one_of)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m require_at_least_one_of \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m {chan \u001b[38;5;28;01mfor\u001b[39;00m chan, _ \u001b[38;5;129;01min\u001b[39;00m filtered} \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(require_at_least_one_of):\n\u001b[0;32m--> 157\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust write to at least one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequire_at_least_one_of\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         )\n\u001b[1;32m    160\u001b[0m write: TYPE_SEND \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m][CONFIG_KEY_SEND]\n\u001b[1;32m    161\u001b[0m write(filtered)\n",
      "\u001b[0;31mInvalidUpdateError\u001b[0m: Must write to at least one of ['user_profile', 'market_analysis', 'stock_recommendations', 'final_report']"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, List, Any\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import requests\n",
    "\n",
    "# Set up your API keys\n",
    "TAVILY_API_KEY = os.environ.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Initialize ChatOpenAI\n",
    "llm = AzureChatOpenAI(openai_api_version=os.environ.get(\"AZURE_OPENAI_VERSION\", \"2023-07-01-preview\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt4chat\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"https://gpt-4-trails.openai.azure.com/\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_KEY\"))\n",
    "\n",
    "# Define the state\n",
    "class State(Dict):\n",
    "    user_profile: Dict\n",
    "    market_analysis: Dict\n",
    "    stock_recommendations: List\n",
    "    final_report: str\n",
    "\n",
    "# User Profiler Agent\n",
    "def user_profiler(state):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=\"You are a financial advisor tasked with gathering user information for investment recommendations.\"),\n",
    "        HumanMessage(content=\"Ask the user about their risk tolerance (conservative, moderate, aggressive), investment amount, and investment time horizon.\")\n",
    "    ])\n",
    "    response = llm(prompt.format_messages())\n",
    "    # In a real implementation, you would process user responses here\n",
    "    state[\"user_profile\"] = {\n",
    "        \"risk_tolerance\": \"moderate\",\n",
    "        \"investment_amount\": 10000,\n",
    "        \"time_horizon\": 5\n",
    "    }\n",
    "    return state\n",
    "\n",
    "# Market Analyzer Agent\n",
    "def market_analyzer(state):\n",
    "    def tavily_search(query):\n",
    "        url = \"https://api.tavily.com/search\"\n",
    "        params = {\n",
    "            \"api_key\": TAVILY_API_KEY,\n",
    "            \"query\": query,\n",
    "            \"search_depth\": \"advanced\",\n",
    "            \"include_domains\": [\"finance.yahoo.com\", \"seekingalpha.com\", \"fool.com\"]\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        return response.json()\n",
    "\n",
    "    market_data = tavily_search(\"current stock market trends and analysis\")\n",
    "    state[\"market_analysis\"] = {\n",
    "        \"trends\": market_data[\"results\"][:3],  # Simplified for this example\n",
    "        \"overall_sentiment\": \"bullish\"  # This would be derived from the analysis in a full implementation\n",
    "    }\n",
    "    return state\n",
    "\n",
    "# Stock Screener Agent\n",
    "def stock_screener(state):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=\"You are a stock screening AI. Based on the user profile and market analysis, recommend 5 stocks.\"),\n",
    "        HumanMessage(content=f\"User Profile: {state['user_profile']}\\nMarket Analysis: {state['market_analysis']}\\nRecommend 5 stocks.\")\n",
    "    ])\n",
    "    response = llm(prompt.format_messages())\n",
    "    state[\"stock_recommendations\"] = response.content.split(\"\\n\")  # Simplified parsing\n",
    "    return state\n",
    "\n",
    "# Report Generator Agent\n",
    "def report_generator(state):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=\"You are a financial report writer. Create a detailed investment report based on the given information.\"),\n",
    "        HumanMessage(content=f\"User Profile: {state['user_profile']}\\nMarket Analysis: {state['market_analysis']}\\nStock Recommendations: {state['stock_recommendations']}\\nCreate a detailed report.\")\n",
    "    ])\n",
    "    response = llm(prompt.format_messages())\n",
    "    state[\"final_report\"] = response.content\n",
    "    return state\n",
    "\n",
    "# Define the graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"user_profiler\", user_profiler)\n",
    "workflow.add_node(\"market_analyzer\", market_analyzer)\n",
    "workflow.add_node(\"stock_screener\", stock_screener)\n",
    "workflow.add_node(\"report_generator\", report_generator)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"user_profiler\", \"market_analyzer\")\n",
    "workflow.add_edge(\"market_analyzer\", \"stock_screener\")\n",
    "workflow.add_edge(\"stock_screener\", \"report_generator\")\n",
    "workflow.add_edge(\"report_generator\", END)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(\"user_profiler\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the graph\n",
    "inputs = {}  # You can add initial inputs here if needed\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(result[\"final_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
